# ğŸ©º Diabetes Prediction Project

## ğŸ¥ Demo
![Demo](demo.gif)

---

## ğŸ“Œ Project Overview
This project aims to predict diabetes outcomes using machine learning models. The dataset includes clinical and demographic features such as Age, BMI, Glucose levels, Insulin, Pregnancies, and Diabetes Pedigree Function.  

Before training, the data was carefully handled for **missing values** and **outliers** to ensure high-quality input for the models.

---

## ğŸ—‚ï¸ Dataset
- **Source:** Local dataset (e.g., Pima Indians Diabetes Dataset)  
- **Number of features:** 8 original features + engineered features  
- **Number of samples:** Variable (training/testing)  
- **Feature Handling:**  
  - âŒ Missing values were imputed  
  - âš ï¸ Outliers were detected and treated  
  - ğŸ“ Feature scaling (StandardScaler) and log transformation applied to skewed features  
  - ğŸ› ï¸ Additional engineered features created:  
    - `Glucose_BMI = Glucose Ã— BMI`  
    - `Pregnancy_per_Age = Pregnancies Ã· Age`  
    - `Glucose_Insulin_ratio = Glucose Ã· Insulin`  
  - ğŸ‘¶ Dummy encoding for age groups (Young, Middle, Old) and BMI groups (Underweight, Normal, Overweight, Obese)  

---

## ğŸš€ Project Steps

### 1ï¸âƒ£ Data Preprocessing
- Imputed missing values  
- Detected and handled outliers  
- Applied **log transformation** to skewed features (`Pregnancies`, `Age`, `Insulin`, `DiabetesPedigreeFunction`)  
- Scaled all features using **StandardScaler**  
- Created engineered features and dummy variables as described above  

### 2ï¸âƒ£ Train-Test Split
- Split dataset into training (80%) and testing (20%) sets  
- Stratified splitting to maintain class distribution  

### 3ï¸âƒ£ Model Training
- **Models trained:**  
  - Logistic Regression  
  - SVM (RBF)  
  - Random Forest  
  - XGBoost  
- Hyperparameter tuning using `RandomizedSearchCV` or `GridSearchCV`  
- **SMOTE** used in pipelines to handle class imbalance  
- Pipelines include preprocessing steps to ensure transformations are applied consistently  

### 4ï¸âƒ£ Model Evaluation
**Metrics computed:**  
- Accuracy  
- ROC-AUC  
- Precision, Recall, F1-score for each class  
- Train accuracy also checked to monitor overfitting  

| Model               | Train Accuracy | Test Accuracy | ROC-AUC |
|--------------------|----------------|----------------|---------|
| Logistic Regression | 0.839          | 0.779          | 0.869   |
| SVM (RBF)           | 0.896          | 0.864          | 0.912   |
| Random Forest       | 0.985          | 0.870          | 0.944   |
| XGBoost             | 0.957         | 0.896          | 0.955   |

---

### 5ï¸âƒ£ Model Deployment
- Overall Best Model: **XGBoost**, based on **ROC-AUC**, **accuracy**, and **F1-score**.
- Model saved with **joblib** for deployment in **Streamlit** or other applications  
- Streamlit app can take new patient data as input and output **predicted diabetes outcome** and **probability**


This project demonstrates the **end-to-end machine learning workflow** for healthcare predictions, including preprocessing, feature engineering, model training, evaluation, and deployment.

---

## ğŸš€ Live Demo
You can try the app directly here: [Diabetes Risk Predictor]([https://gtc-ml-project2-diabetes-prediction-rjbqteuxmu9vpp34hemytp.streamlit.app/])
